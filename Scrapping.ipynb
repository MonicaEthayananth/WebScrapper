{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#web destination to scrap from\n",
    "url = \"https://www.zim.com/tools/track-a-shipment?consnumber=ZIMUSNH7160462\"\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "#lets find all table in this URL address\n",
    "# tables = soup.find_all('table')\n",
    "# print(tables)\n",
    "#narrowing down to table of interest\n",
    "# trackingTable = soup.find_all('table',{'routing-table track-shipment-table page-results'})\n",
    "# print(trackingTable)\n",
    "mainRows = []\n",
    "tableMain = soup.find_all('table',{'opener'})\n",
    "for tabM in tableMain:\n",
    "    temp1 = tabM.find_all('td')\n",
    "#     print(temp1)\n",
    "    mainString = str(temp1)\n",
    "    cleanMain = BeautifulSoup(mainString,'lxml').get_text()\n",
    "#     print(cleanMain)\n",
    "    mainRows.append(cleanMain)\n",
    "#     print(mainRows)\n",
    "df2 = pd.DataFrame(mainRows)\n",
    "\n",
    "df2[0] = df2[0].str.strip('[')\n",
    "df2[0]=df2[0].str.strip(']')\n",
    "df2.head()\n",
    "df3 = df2[0].str.split(',',expand=True)\n",
    "df3.head()\n",
    "df3.columns = ['Container','Last Activity','Location','Loaction2','Date','Vessel/Voyage']\n",
    "# df3.head()\n",
    "#data frame for the main row\n",
    "subRows = []\n",
    "tableSub = soup.find_all('tr',{''})\n",
    "for tabS in tableSub:\n",
    "    temp2 = tabS.find_all('td')\n",
    "#     print(temp2)\n",
    "    subString = str(temp2)\n",
    "    cleanSub = BeautifulSoup(subString,'lxml').get_text()\n",
    "#     print(cleanSub)\n",
    "    subRows.append(cleanSub)\n",
    "#     print(subRows)\n",
    "df4 = pd.DataFrame(subRows)\n",
    "\n",
    "df4[0] = df4[0].str.strip('[')\n",
    "df4[0]=df4[0].str.strip(']')\n",
    "df4.head()\n",
    "df5 = df4[0].str.split(',',expand=True)\n",
    "df5.head(5)\n",
    "### merge all dataframes\n",
    "df5.columns = ['Container','Last Activity','Location','Loaction2','Date','Vessel/Voyage']\n",
    "# df51.head()\n",
    "mergeFrames = [df3,df5]\n",
    "mf1 = pd.concat(mergeFrames)\n",
    "mf1.head(10)\n",
    "# mf2 = mf1.dropna(axis=0, how='any')\n",
    "mf1.to_csv(\"ScrappedData11.csv\", index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shipping detail2\n",
    "url = \"https://www.zim.com/tools/track-a-shipment?consnumber=ZIMUSEL766825\"\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "# trackingTable = soup.find_all('table',{'routing-table track-shipment-table page-results'})\n",
    "mainRows1 = []\n",
    "tableMain = soup.find_all('table',{'opener'})\n",
    "for tabM in tableMain:\n",
    "    temp1 = tabM.find_all('td')\n",
    "#     print(temp1)\n",
    "    mainString = str(temp1)\n",
    "    cleanMain = BeautifulSoup(mainString,'lxml').get_text()\n",
    "#     print(cleanMain)\n",
    "    mainRows1.append(cleanMain)\n",
    "#     print(mainRows)\n",
    "df21 = pd.DataFrame(mainRows1)\n",
    "\n",
    "df21[0] = df21[0].str.strip('[')\n",
    "df21[0]=df21[0].str.strip(']')\n",
    "# df21.head()\n",
    "df31 = df21[0].str.split(',',expand=True)\n",
    "# df31.head()\n",
    "df31.columns = ['Container','Last Activity','Location','Loaction2','Date','Vessel/Voyage']\n",
    "# df31.head()\n",
    "subRows1 = []\n",
    "tableSub = soup.find_all('tr',{''})\n",
    "for tabS in tableSub:\n",
    "    temp2 = tabS.find_all('td')\n",
    "#     print(temp2)\n",
    "    subString = str(temp2)\n",
    "    cleanSub = BeautifulSoup(subString,'lxml').get_text()\n",
    "#     print(cleanSub)\n",
    "    subRows1.append(cleanSub)\n",
    "#     print(subRows)\n",
    "df41 = pd.DataFrame(subRows)\n",
    "\n",
    "df41[0] = df41[0].str.strip('[')\n",
    "df41[0]=df41[0].str.strip(']')\n",
    "# df41.head()\n",
    "df51 = df41[0].str.split(',',expand=True)\n",
    "# df51.head(5)\n",
    "df51.columns = ['Container','Last Activity','Location','Loaction2','Date','Vessel/Voyage']\n",
    "# df51.head()\n",
    "mergeFrames = [df31,df51]\n",
    "mf11 = pd.concat(mergeFrames)\n",
    "mf11.head(10)\n",
    "mf11.to_csv(\"ScrappedData2.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shipping detail2\n",
    "url = \"https://www.zim.com/tools/track-a-shipment?consnumber=ZIMUSEL766829\"\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "# trackingTable = soup.find_all('table',{'routing-table track-shipment-table page-results'})\n",
    "mainRows2 = []\n",
    "tableMain = soup.find_all('table',{'opener'})\n",
    "for tabM in tableMain:\n",
    "    temp1 = tabM.find_all('td')\n",
    "#     print(temp1)\n",
    "    mainString = str(temp1)\n",
    "    cleanMain = BeautifulSoup(mainString,'lxml').get_text()\n",
    "#     print(cleanMain)\n",
    "    mainRows2.append(cleanMain)\n",
    "#     print(mainRows)\n",
    "df22 = pd.DataFrame(mainRows2)\n",
    "\n",
    "df22[0] = df22[0].str.strip('[')\n",
    "df22[0]=df22[0].str.strip(']')\n",
    "# df21.head()\n",
    "df32 = df22[0].str.split(',',expand=True)\n",
    "# df31.head()\n",
    "df32.columns = ['Container','Last Activity','Location','Loaction2','Date','Vessel/Voyage']\n",
    "# df32.head()\n",
    "subRows2 = []\n",
    "tableSub = soup.find_all('tr',{''})\n",
    "for tabS in tableSub:\n",
    "    temp2 = tabS.find_all('td')\n",
    "#     print(temp2)\n",
    "    subString = str(temp2)\n",
    "    cleanSub = BeautifulSoup(subString,'lxml').get_text()\n",
    "#     print(cleanSub)\n",
    "    subRows2.append(cleanSub)\n",
    "#     print(subRows)\n",
    "df42 = pd.DataFrame(subRows2)\n",
    "\n",
    "df42[0] = df42[0].str.strip('[')\n",
    "df42[0]=df42[0].str.strip(']')\n",
    "# df41.head()\n",
    "df52 = df42[0].str.split(',',expand=True)\n",
    "# df51.head(5)\n",
    "df52.columns = ['Container','Last Activity','Location','Loaction2','Date','Vessel/Voyage']\n",
    "df52.head()\n",
    "mergeFrames = [df32,df52]\n",
    "mf12 = pd.concat(mergeFrames)\n",
    "mf12.head(10)\n",
    "mf12.to_csv(\"ScrappedData3.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shipping detail3\n",
    "url = \"https://www.zim.com/tools/track-a-shipment?consnumber=ZIMUSNH20097314\"\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "# trackingTable = soup.find_all('table',{'routing-table track-shipment-table page-results'})\n",
    "mainRows3 = []\n",
    "tableMain = soup.find_all('table',{'opener'})\n",
    "for tabM in tableMain:\n",
    "    temp1 = tabM.find_all('td')\n",
    "#     print(temp1)\n",
    "    mainString = str(temp1)\n",
    "    cleanMain = BeautifulSoup(mainString,'lxml').get_text()\n",
    "#     print(cleanMain)\n",
    "    mainRows3.append(cleanMain)\n",
    "#     print(mainRows)\n",
    "df23 = pd.DataFrame(mainRows3)\n",
    "\n",
    "df23[0] = df23[0].str.strip('[')\n",
    "df23[0]=df23[0].str.strip(']')\n",
    "# df21.head()\n",
    "df33 = df23[0].str.split(',',expand=True)\n",
    "# df31.head()\n",
    "df33.columns = ['Container','Last Activity','Location','Loaction2','Date','Vessel/Voyage']\n",
    "# df32.head()\n",
    "subRows3 = []\n",
    "tableSub = soup.find_all('tr',{''})\n",
    "for tabS in tableSub:\n",
    "    temp2 = tabS.find_all('td')\n",
    "#     print(temp2)\n",
    "    subString = str(temp2)\n",
    "    cleanSub = BeautifulSoup(subString,'lxml').get_text()\n",
    "#     print(cleanSub)\n",
    "    subRows3.append(cleanSub)\n",
    "#     print(subRows)\n",
    "df43 = pd.DataFrame(subRows3)\n",
    "\n",
    "df43[0] = df43[0].str.strip('[')\n",
    "df43[0]=df43[0].str.strip(']')\n",
    "# df41.head()\n",
    "df53 = df43[0].str.split(',',expand=True)\n",
    "# df51.head(5)\n",
    "df53.columns = ['Container','Last Activity','Location','Loaction2','Date','Vessel/Voyage']\n",
    "df53.head()\n",
    "mergeFrames = [df33,df53]\n",
    "mf13 = pd.concat(mergeFrames)\n",
    "mf13.head(10)\n",
    "mf13.to_csv(\"ScrappedData4.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shipping detail5\n",
    "url = \"https://www.zim.com/tools/track-a-shipment?consnumber=ZIMUSEL200190230\"\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "# trackingTable = soup.find_all('table',{'routing-table track-shipment-table page-results'})\n",
    "mainRows5 = []\n",
    "tableMain = soup.find_all('table',{'opener'})\n",
    "for tabM in tableMain:\n",
    "    temp1 = tabM.find_all('td')\n",
    "#     print(temp1)\n",
    "    mainString = str(temp1)\n",
    "    cleanMain = BeautifulSoup(mainString,'lxml').get_text()\n",
    "#     print(cleanMain)\n",
    "    mainRows5.append(cleanMain)\n",
    "#     print(mainRows)\n",
    "df25 = pd.DataFrame(mainRows5)\n",
    "\n",
    "df25[0] = df25[0].str.strip('[')\n",
    "df25[0]=df25[0].str.strip(']')\n",
    "# df21.head()\n",
    "df35 = df25[0].str.split(',',expand=True)\n",
    "# df31.head()\n",
    "df35.columns = ['Container','Last Activity','Location','Loaction2','Date','Vessel/Voyage']\n",
    "# df34.head()\n",
    "subRows5 = []\n",
    "tableSub = soup.find_all('tr',{''})\n",
    "for tabS in tableSub:\n",
    "    temp2 = tabS.find_all('td')\n",
    "#     print(temp2)\n",
    "    subString = str(temp2)\n",
    "    cleanSub = BeautifulSoup(subString,'lxml').get_text()\n",
    "#     print(cleanSub)\n",
    "    subRows5.append(cleanSub)\n",
    "#     print(subRows)\n",
    "df45 = pd.DataFrame(subRows5)\n",
    "\n",
    "df45[0] = df45[0].str.strip('[')\n",
    "df45[0]=df45[0].str.strip(']')\n",
    "# df41.head()\n",
    "df55 = df45[0].str.split(',',expand=True)\n",
    "# df51.head(5)\n",
    "df55.columns = ['Container','Last Activity','Location','Loaction2','Date','Vessel/Voyage']\n",
    "# df54.head()\n",
    "mergeFrames = [df34,df54]\n",
    "mf15 = pd.concat(mergeFrames)\n",
    "mf15.head(10)\n",
    "mf15.to_csv(\"ScrappedData5.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
